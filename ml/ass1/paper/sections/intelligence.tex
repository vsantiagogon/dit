At this point, our assesment of machine intelligence is quite negative: they 
aren't capable to perform the most basic tasks they need to start working, they 
can't contextualize their scope. They aren't understanding the problems they 
claimed to had learnt. And they aren't using any magical reasoning, but basic 
geometric transformations.

Still, someone could argue (maybe Mr Kurzweil himself) that some systems are 
outperforming humans in some areas: Didn't Deep Blue win Kasparov? Didn't IBM's 
Watson win Jeopardy?

No, they didn't.

None of these machines decided by its own to train his skills in order to 
participate in the contest. Humans did.

And this is a big \textit{no}. Because, in my opinion, what truly defines 
intelligence is

\textcolor{gray}{
	\Large{
		the ability to come up with questions, not the ability to provide 
		answers.
	}
}

Chances are that the post-singularity world (if any) will be populated by 
millions of super-skilled machines quietly waiting for instructions. Doing nothing.