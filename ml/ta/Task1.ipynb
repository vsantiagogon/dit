{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK1: Naive Bayes, three categories including headers, footers and quotes and stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "     comp.graphics       0.94      0.87      0.91       389\n",
      "rec.sport.baseball       0.94      0.99      0.97       397\n",
      "   sci.electronics       0.91      0.93      0.92       393\n",
      "\n",
      "       avg / total       0.93      0.93      0.93      1179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "categories = ['rec.sport.baseball', 'sci.electronics', 'comp.graphics']\n",
    "twentyTrain = fetch_20newsgroups(subset='train', \n",
    "                                 categories=categories, \n",
    "                                 shuffle=True,\n",
    "                                 random_state=42\n",
    "                                )\n",
    "\n",
    "twentyTrain.target_names\n",
    "\n",
    "count_vect = CountVectorizer()        #can change this with analyser and ngram_range params for char n-grams\n",
    "count_vect  #shows the default parameters\n",
    "\n",
    "tdm = count_vect.fit_transform(twentyTrain.data)   #tdm is a matrix - 2-d array\n",
    "\n",
    "transformer = TfidfTransformer()   \n",
    "transformer   #check parameters - they allow for tf vs tfidf and l1 vs l2 normalisation\n",
    "\n",
    "tdm_tfidf = transformer.fit_transform(tdm)   #transform the TDM\n",
    "tdm_tfidf.shape\n",
    "\n",
    "\n",
    "clf = MultinomialNB().fit(tdm_tfidf, twentyTrain.target)    #build the classifier (data, classes)\n",
    "\n",
    "docs_test = ['I am sick', 'No more gun control']      #set up 2 test instances\n",
    "\n",
    "# transform the test data in the same way as the training through CountVector and TfidfTransformer\n",
    "test_counts = count_vect.transform(docs_test)       # don't fit as the vocab has been generated from the training data\n",
    "test_tfidf = transformer.transform(test_counts)\n",
    "\n",
    "predicted = clf.predict(test_tfidf)   #predict  \n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                      ('tfidf', TfidfTransformer()),\n",
    "                      ('clf', MultinomialNB()),])\n",
    "\n",
    "text_clf.fit(twentyTrain.data, twentyTrain.target)  \n",
    "\n",
    "twenty_test = fetch_20newsgroups(subset='test', \n",
    "                                 categories=categories, \n",
    "                                 shuffle=True, \n",
    "                                 random_state=42)  \n",
    "docs_test = twenty_test.data\n",
    "\n",
    "predicted = text_clf.predict(docs_test)   # predict\n",
    "np.mean(predicted == twenty_test.target)  #report accuracy\n",
    "\n",
    "print(metrics.classification_report(twenty_test.target, predicted,\n",
    "    target_names=twenty_test.target_names))    #print classification results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
