{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Feature selection classes\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "# Classifiers\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# metrics\n",
    "from sklearn import metrics\n",
    "\n",
    "def showMetrics(targets, predictions, names):\n",
    "    print(metrics.classification_report(targets, predictions, target_names=names))\n",
    "    print(\"Accuracy = %6.4f \" % metrics.accuracy_score(targets, predictions))\n",
    "    print(\"Avg recall, micro = %6.4f\" % metrics.recall_score(targets, predictions, average = 'micro'))\n",
    "    print(\"Avg recall, macro = %6.4f\" % metrics.recall_score(targets, predictions, average = 'macro'))\n",
    "    print(\"Avg precision, macro=%6.4f\" % metrics.precision_score(targets, predictions, average = 'macro'))\n",
    "\n",
    "categories = ['talk.religion.misc', 'soc.religion.christian'];    \n",
    "\n",
    "train = fetch_20newsgroups(\n",
    "            subset = 'train',\n",
    "            categories = categories,\n",
    "            remove = ('headers', 'footers', 'quotes'),\n",
    "            shuffle = True, \n",
    "            random_state = 42\n",
    "        )\n",
    "\n",
    "test = fetch_20newsgroups(\n",
    "            subset='test',     # get test data\n",
    "            categories=categories,\n",
    "            remove=('headers', 'footers', 'quotes'),\n",
    "            shuffle=True,\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "def classifier(train, test, use_stop_words):\n",
    "\n",
    "    X, Y = train.data, train.target\n",
    "\n",
    "    if use_stop_words:\n",
    "        vectorizer = TfidfVectorizer()\n",
    "    else:\n",
    "        vectorizer = TfidfVectorizer(max_df=0.95, min_df=3, analyzer='word', stop_words=\"english\")\n",
    "\n",
    "    X_vec = vectorizer.fit_transform(X)   #transform training data\n",
    "\n",
    "    fs = SelectKBest(chi2, k=100)    #get top k features \n",
    "    X_fs_vec= fs.fit_transform(X_vec, Y)  # fit and transform tdm to reduced feature space\n",
    "\n",
    "    vectors_test = vectorizer.transform(test.data)   #transform test data\n",
    "        \n",
    "    fs_test      = fs.transform(vectors_test)     # transform test data to reduced feature space\n",
    "    classifier = MultinomialNB(alpha=.01)\n",
    "    classifier.fit(X_fs_vec, Y)\n",
    "    return classifier.predict(fs_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------\n",
      "Classifying over TEST dataset.\n",
      "------------------------------\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "soc.religion.christian       0.69      0.96      0.80       398\n",
      "    talk.religion.misc       0.84      0.31      0.45       251\n",
      "\n",
      "           avg / total       0.75      0.71      0.67       649\n",
      "\n",
      "Accuracy = 0.7088 \n",
      "Avg recall, micro = 0.7088\n",
      "Avg recall, macro = 0.6345\n",
      "Avg precision, macro=0.7623\n",
      "\n",
      "\n",
      "-------------------------------\n",
      "Classifying over TRAIN dataset.\n",
      "-------------------------------\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "soc.religion.christian       0.77      1.00      0.87       599\n",
      "    talk.religion.misc       1.00      0.53      0.69       377\n",
      "\n",
      "           avg / total       0.86      0.82      0.80       976\n",
      "\n",
      "Accuracy = 0.8176 \n",
      "Avg recall, micro = 0.8176\n",
      "Avg recall, macro = 0.7639\n",
      "Avg precision, macro=0.8855\n",
      "\n",
      "\n",
      "-----------------------------\n",
      "Classifying using STOP WORDS.\n",
      "-----------------------------\n",
      "\n",
      "\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "     comp.graphics       0.83      0.76      0.79       389\n",
      "rec.sport.baseball       0.65      0.95      0.77       397\n",
      "   sci.electronics       0.86      0.53      0.66       393\n",
      "\n",
      "       avg / total       0.78      0.75      0.74      1179\n",
      "\n",
      "Accuracy = 0.7464 \n",
      "Avg recall, micro = 0.7464\n",
      "Avg recall, macro = 0.7457\n",
      "Avg precision, macro=0.7795\n",
      "\n",
      "\n",
      "-------------------------------\n",
      "Classifying WITHOUT STOP WORDS \n",
      "-------------------------------\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "     comp.graphics       0.83      0.76      0.79       389\n",
      "rec.sport.baseball       0.63      0.97      0.76       397\n",
      "   sci.electronics       0.94      0.49      0.64       393\n",
      "\n",
      "       avg / total       0.80      0.74      0.73      1179\n",
      "\n",
      "Accuracy = 0.7413 \n",
      "Avg recall, micro = 0.7413\n",
      "Avg recall, macro = 0.7406\n",
      "Avg precision, macro=0.7972\n"
     ]
    }
   ],
   "source": [
    "print(\"-------------------------------\")\n",
    "print(\"Classifying over TEST dataset.\")\n",
    "print(\"------------------------------\")\n",
    "\n",
    "\n",
    "predicted = classifier(train, test, False)\n",
    "\n",
    "showMetrics(test.target, predicted, test.target_names)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-------------------------------\")\n",
    "print(\"Classifying over TRAIN dataset.\")\n",
    "print(\"-------------------------------\")\n",
    "\n",
    "predicted = classifier(train, train, False)\n",
    "\n",
    "showMetrics(train.target, predicted, train.target_names)\n",
    "\n",
    "##############################################################\n",
    "# Now we change the datasets to use 3 different categories.\n",
    "##############################################################\n",
    "\n",
    "categories = ['rec.sport.baseball', 'sci.electronics', 'comp.graphics'];    \n",
    "\n",
    "train = fetch_20newsgroups(\n",
    "            subset = 'train',\n",
    "            categories = categories,\n",
    "            remove = ('headers', 'footers', 'quotes'),\n",
    "            shuffle = True, \n",
    "            random_state = 42\n",
    "        )\n",
    "\n",
    "test = fetch_20newsgroups(\n",
    "            subset='test',     # get test data\n",
    "            categories=categories,\n",
    "            remove=('headers', 'footers', 'quotes'),\n",
    "            shuffle=True,\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "print('\\n');\n",
    "print(\"-----------------------------\")\n",
    "print(\"Classifying using STOP WORDS.\")\n",
    "print(\"-----------------------------\")\n",
    "print(\"\\n\")\n",
    "\n",
    "predicted = classifier(train, test, True)\n",
    "\n",
    "showMetrics(test.target, predicted, test.target_names)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-------------------------------\")\n",
    "print(\"Classifying WITHOUT STOP WORDS \")\n",
    "print(\"-------------------------------\")\n",
    "\n",
    "predicted = classifier(train, test, False)\n",
    "\n",
    "showMetrics(test.target, predicted, test.target_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answers\n",
    "\n",
    "TASK1.\n",
    "\n",
    "The sample is unbalanced. There's more documents under \"talk.religion.misc\" category than \"soc.religion.christian\".\n",
    "\n",
    "The precision (and overall performance) is better when we classify over the TRAIN dataset. That makes sense, because we have trained the classifier on this dataset.\n",
    "\n",
    "A mix of Precission, Accuracy and Recall should be considered to asses algorithm's performance.\n",
    "\n",
    "TASK2.\n",
    "\n",
    "Classifying without stop word has an overall better performanc, according to precision. Specifically improves sci.electronics precision. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
