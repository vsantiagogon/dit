{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Investigate the impact of class imbalance on performance measures\n",
    "\n",
    "Build a classifier that predicts the categories 'talk.religion.misc' and 'soc.religion.christian' from the 20-newsgroups dataset.  \n",
    "Test it first on the training set.\n",
    "Test it also on the test set.  \n",
    "\n",
    "Add a markdown cell and include your observations on the following:\n",
    "* the class distribution of the training set  (evident from the classification report of testing on the training set -  support = the number of instances of each class)\n",
    "* the performance on the training set versus the performance on the test set and what does any difference here mean\n",
    "* which performance measure should be used.\n",
    "\n",
    "Note that a Jupyter notebooks Markdown Cheatsheet is available at https://medium.com/ibm-data-science-experience/markdown-for-jupyter-notebooks-cheatsheet-386c05aeebed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Feature selection classes\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "# Classifiers\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# metrics\n",
    "from sklearn import metrics\n",
    "\n",
    "def showMetrics(targets, predictions, names):\n",
    "    print(metrics.classification_report(targets, predictions, target_names=names))\n",
    "    print(\"Accuracy = %6.4f \" % metrics.accuracy_score(targets, predictions))\n",
    "    print(\"Avg recall, micro = %6.4f\" % metrics.recall_score(targets, predictions, average = 'micro'))\n",
    "    print(\"Avg recall, macro = %6.4f\" % metrics.recall_score(targets, predictions, average = 'macro'))\n",
    "    print(\"Avg precision, macro=%6.4f\" % metrics.precision_score(targets, predictions, average = 'macro'))\n",
    "    \n",
    "def predict(categories, stop_words, dataset = 'test'):\n",
    "\n",
    "    newsgroups_train = fetch_20newsgroups(subset='train',\n",
    "                                         categories=categories,\n",
    "                                         remove=('headers', 'footers', 'quotes'),\n",
    "                                         shuffle=True, random_state=42)\n",
    "\n",
    "    X, Y = newsgroups_train.data, newsgroups_train.target\n",
    "\n",
    "    if stop_words:\n",
    "        vectorizer = TfidfVectorizer()\n",
    "    else:\n",
    "        vectorizer = TfidfVectorizer(max_df=0.95, min_df=3, stop_words=\"english\")\n",
    "\n",
    "    X_vec = vectorizer.fit_transform(X)   #transform training data\n",
    "\n",
    "    fs = SelectKBest(chi2, k=100)    #get top k features \n",
    "    X_fs_vec= fs.fit_transform(X_vec, Y)  # fit and transform tdm to reduced feature space\n",
    "\n",
    "    newsgroups_test = fetch_20newsgroups(subset='test',     # get test data\n",
    "                                         categories=categories,\n",
    "                                         remove=('headers', 'footers', 'quotes'),\n",
    "                                         shuffle=True,\n",
    "                                         random_state=42)\n",
    "\n",
    "    classifier = MultinomialNB(alpha=.01)\n",
    "    classifier.fit(X_fs_vec, Y)\n",
    "\n",
    "    if dataset == 'test':\n",
    "        vectors_test = vectorizer.transform(newsgroups_test.data)   #transform test data\n",
    "        fs_set = fs.transform(vectors_test)     # transform test data to reduced feature space\n",
    "    else:\n",
    "        vectors_train = vectorizer.transform(newsgroups_train.data)   #transform test data\n",
    "        fs_set = fs.transform(vectors_train)     # transform test data to reduced feature space\n",
    "    \n",
    "    return classifier.predict(fs_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------\n",
      "Classifying over TEST dataset.\n",
      "------------------------------\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "soc.religion.christian       0.69      0.96      0.80       398\n",
      "    talk.religion.misc       0.84      0.31      0.45       251\n",
      "\n",
      "           avg / total       0.75      0.71      0.67       649\n",
      "\n",
      "Accuracy = 0.7088 \n",
      "Avg recall, micro = 0.7088\n",
      "Avg recall, macro = 0.6345\n",
      "Avg precision, macro=0.7623\n",
      "-------------------------------\n",
      "Classifying over TRAIN dataset.\n",
      "------------------------------\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "soc.religion.christian       0.77      1.00      0.87       599\n",
      "    talk.religion.misc       1.00      0.53      0.69       377\n",
      "\n",
      "           avg / total       0.86      0.82      0.80       976\n",
      "\n",
      "Accuracy = 0.8176 \n",
      "Avg recall, micro = 0.8176\n",
      "Avg recall, macro = 0.7639\n",
      "Avg precision, macro=0.8855\n"
     ]
    }
   ],
   "source": [
    "categories = ['talk.religion.misc', 'soc.religion.christian']\n",
    "\n",
    "\n",
    "print(\"-------------------------------\")\n",
    "print(\"Classifying over TEST dataset.\")\n",
    "print(\"------------------------------\")\n",
    "\n",
    "\n",
    "predicted = predict(['talk.religion.misc', 'soc.religion.christian'], False, 'test')\n",
    "\n",
    "showMetrics(newsgroups_test.target, predicted, newsgroups_train.target_names)\n",
    "\n",
    "print(\"-------------------------------\")\n",
    "print(\"Classifying over TRAIN dataset.\")\n",
    "print(\"------------------------------\")\n",
    "\n",
    "predicted = predicted = predict(['talk.religion.misc', 'soc.religion.christian'], False, 'train')\n",
    "\n",
    "showMetrics(newsgroups_train.target, predicted, newsgroups_train.target_names)\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answers\n",
    "\n",
    "The sample is unbalanced. There's more documents under \"talk.religion.misc\" category than \"soc.religion.christian\".\n",
    "\n",
    "The precision (and overall performance) is better when we classify over the TRAIN dataset. That makes sense, because we have trained the classifier on this dataset.\n",
    "\n",
    "A mix of Precission, Accuracy and Recall should be considered to asses algorithm's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Investigate the impact of stopword removal and DF reduction on performance\n",
    "\n",
    "Build a classifier on at least 3 categories of the 20-newsgroup dataset.  Measure the performance including stopword removal and various levels of document frequency reduction.\n",
    "\n",
    "Add a markdown cell and outline your results showing the number of features used by the different settings and the impact on performance, if any.      \n",
    "\n",
    "Justify your choice of performance measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------\n",
      "PREDICTIONS WITHOUT STOP WORDS\n",
      "-------------------------------\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "soc.religion.christian       0.69      0.96      0.80       398\n",
      "    talk.religion.misc       0.84      0.31      0.45       251\n",
      "\n",
      "           avg / total       0.75      0.71      0.67       649\n",
      "\n",
      "Accuracy = 0.7088 \n",
      "Avg recall, micro = 0.7088\n",
      "Avg recall, macro = 0.6345\n",
      "Avg precision, macro=0.7623\n",
      "----------------------------\n",
      "PREDICTIONS WITH STOP WORDS\n",
      "---------------------------\n"
     ]
    }
   ],
   "source": [
    "print('-------------------------------')\n",
    "print(\"PREDICTIONS WITHOUT STOP WORDS\")\n",
    "print('-------------------------------')\n",
    "\n",
    "predicted = predict(['talk.religion.misc', 'soc.religion.christian'], False, 'test')\n",
    "\n",
    "showMetrics(newsgroups_test.target, predicted, newsgroups_train.target_names)\n",
    "\n",
    "print('----------------------------')\n",
    "print(\"PREDICTIONS WITH STOP WORDS\")\n",
    "print('---------------------------')\n",
    "\n",
    "predicted = predict(['talk.religion.misc', 'soc.religion.christian'], True, 'test')\n",
    "\n",
    "showMetrics(newsgroups_test.target, predicted, newsgroups_train.target_names)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
