{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Feature selection classes\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "# Classifiers\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# metrics\n",
    "from sklearn import metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and generate TDM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categories = ['rec.sport.baseball', 'rec.sport.hockey']\n",
    "newsgroups_train = fetch_20newsgroups(subset='train',\n",
    "                                     categories=categories,\n",
    "                                     remove=('headers', 'footers', 'quotes'),\n",
    "                                     shuffle=True, random_state=42)\n",
    "\n",
    "X, Y = newsgroups_train.data, newsgroups_train.target\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "X_vec = vectorizer.fit_transform(X)   #transform training data into TDM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine the features generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 14023\n",
      "First 100: ['00', '000', '000th', '002', '005', '007', '01', '011', '013', '013939', '014', '015', '016', '019', '02', '020', '021', '023', '024', '025', '027', '029', '03', '036', '037', '038', '039', '04', '040', '041', '042', '043', '0435', '044', '0458', '0483', '05', '050', '051', '052', '053', '055', '056', '059', '06', '065', '0666', '067', '069', '07', '070', '071', '072', '075', '077', '079', '08', '083', '086', '087', '088', '089', '08903', '09', '091', '094', '095', '097', '099', '10', '100', '1000', '1001', '1003', '1004', '1005', '1006', '1007', '1008', '101', '1010', '1012', '1013', '1014', '1015', '1016', '1017', '1018', '1019', '102', '1020', '1021', '1022', '1023', '1024', '1025', '1026', '1027', '1028', '10280']\n"
     ]
    }
   ],
   "source": [
    "ftr_names= vectorizer.get_feature_names()\n",
    "print(\"Number of features: %d\"  % len(ftr_names))\n",
    "print(\"First 100: %s\" % ftr_names[:100])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Stopwords  and add in Document Frequency reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 4779\n",
      "First 100: ['00', '000', '01', '02', '03', '038', '04', '05', '06', '0666', '07', '08', '09', '091', '10', '100', '1000', '101', '1019', '102', '1020', '1029', '103', '1036', '1038', '104', '1046', '105', '106', '1061', '107', '1073', '108', '109', '10th', '11', '110', '111', '112', '113', '114', '1145', '115', '1157', '116', '117', '118', '1186', '119', '11th', '12', '120', '121', '122', '1223', '123', '124', '125', '126', '1262', '127', '128', '129', '13', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '14', '140', '1400', '141', '142', '143', '1430', '144', '145', '146', '147', '148', '149', '15', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '15th', '16']\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(max_df=0.95, min_df=3, stop_words=\"english\")\n",
    "X_vec = vectorizer.fit_transform(X)   #transform training data\n",
    "\n",
    "ftr_names= vectorizer.get_feature_names()\n",
    "print(\"Number of features: %d\"  % len(ftr_names))\n",
    "print(\"First 100: %s\" % ftr_names[:100])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the Chi-Squared test for feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 575,  579,  663,  730,  808,  814,  835,  836,  847,  852,  992,\n",
       "       1023, 1073, 1088, 1089, 1103, 1206, 1240, 1257, 1423, 1426, 1551,\n",
       "       1555, 1607, 1612, 1747, 1758, 1767, 1900, 1918, 1931, 1967, 2035,\n",
       "       2044, 2049, 2055, 2056, 2060, 2161, 2174, 2230, 2233, 2240, 2289,\n",
       "       2316, 2416, 2426, 2452, 2499, 2538, 2625, 2651, 2682, 2725, 2799,\n",
       "       2827, 2899, 2978, 2985, 3054, 3072, 3087, 3190, 3278, 3280, 3292,\n",
       "       3310, 3337, 3338, 3339, 3340, 3342, 3344, 3364, 3365, 3416, 3497,\n",
       "       3502, 3525, 3552, 3566, 3604, 3737, 3744, 3760, 3765, 3781, 3785,\n",
       "       3941, 4078, 4109, 4110, 4124, 4419, 4469, 4543, 4672, 4673, 4676,\n",
       "       4734])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi = SelectKBest(chi2, k=100)    #get top k features \n",
    "X_chi_vec= chi.fit_transform(X_vec, Y)  #fit and transform  training data (TDM) into the reduced feature space\n",
    "\n",
    "mask = chi.get_support(indices=True) # mask returns a list of indices into the original vocabulary/feature space\n",
    "\n",
    "mask #print out the mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index: 575, feature name: aaa\n",
      "index: 579, feature name: abc\n",
      "index: 663, feature name: alomar\n",
      "index: 730, feature name: arena\n",
      "index: 808, feature name: baerga\n",
      "index: 814, feature name: ball\n",
      "index: 835, feature name: base\n",
      "index: 836, feature name: baseball\n",
      "index: 847, feature name: bat\n",
      "index: 852, feature name: batting\n"
     ]
    }
   ],
   "source": [
    "## access the mask\n",
    "for i in mask[:10]:\n",
    "    print(\"index: %d, feature name: %s\" % (i, ftr_names[i]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 100\n",
      "First 100: ['aaa', 'abc', 'alomar', 'arena', 'baerga', 'ball', 'base', 'baseball', 'bat', 'batting', 'braves', 'bruins', 'calgary', 'canada', 'canadian', 'captain', 'chop', 'clemens', 'coach', 'cubs', 'cup', 'detroit', 'devils', 'dl', 'dodgers', 'era', 'espn', 'european', 'finals', 'flames', 'flyers', 'francis', 'giants', 'gilmour', 'gld', 'gm', 'goal', 'goals', 'hartford', 'hawks', 'hit', 'hitter', 'hockey', 'hr', 'ice', 'islanders', 'jagr', 'jewish', 'keenan', 'kings', 'leafs', 'lemieux', 'lindros', 'lopez', 'manager', 'mask', 'mets', 'montreal', 'morris', 'nhl', 'nl', 'north', 'ottawa', 'penguins', 'pens', 'period', 'phillies', 'pitch', 'pitched', 'pitcher', 'pitchers', 'pitching', 'pittsburgh', 'playoff', 'playoffs', 'pp', 'pts', 'puck', 'quebec', 'rangers', 'rbi', 'reds', 'rockies', 'roger', 'rotation', 'round', 'run', 'runs', 'sharks', 'sox', 'stadium', 'staff', 'stanley', 'traded', 'tv', 'vancouver', 'wings', 'winner', 'winnipeg', 'yankees']\n"
     ]
    }
   ],
   "source": [
    "## create a list of the selected features using the mask\n",
    "new_ftrs = [] # a list to hold your k best features\n",
    "\n",
    "for i in mask:\n",
    "      new_ftrs.append(ftr_names[i])\n",
    "print(\"Number of features: %d\"  % len(new_ftrs))\n",
    "print(\"First 100: %s\" % new_ftrs[:100])        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform classification using chi-squared feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "rec.sport.baseball       0.97      0.66      0.79       397\n",
      "  rec.sport.hockey       0.75      0.98      0.85       399\n",
      "\n",
      "       avg / total       0.86      0.82      0.82       796\n",
      "\n"
     ]
    }
   ],
   "source": [
    "categories = ['rec.sport.baseball', 'rec.sport.hockey']\n",
    "newsgroups_train = fetch_20newsgroups(subset='train',\n",
    "                                     categories=categories,\n",
    "                                     remove=('headers', 'footers', 'quotes'),\n",
    "                                     shuffle=True, random_state=42)\n",
    "\n",
    "X, Y = newsgroups_train.data, newsgroups_train.target\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "X_vec = vectorizer.fit_transform(X)   #transform training data\n",
    "\n",
    "fs = SelectKBest(chi2, k=100)    #get top k features \n",
    "X_fs_vec= fs.fit_transform(X_vec, Y)  # fit and transform tdm to reduced feature space\n",
    "\n",
    "newsgroups_test = fetch_20newsgroups(subset='test',     # get test data\n",
    "                                     categories=categories,\n",
    "                                     remove=('headers', 'footers', 'quotes'),\n",
    "                                     shuffle=True,\n",
    "                                     random_state=42)\n",
    "\n",
    "vectors_test = vectorizer.transform(newsgroups_test.data)   #transform test data\n",
    "fs_test = fs.transform(vectors_test)     # transform test data to reduced feature space\n",
    "\n",
    "classifier = MultinomialNB(alpha=.01)\n",
    "classifier.fit(X_fs_vec, Y)\n",
    "predicted = classifier.predict(fs_test)\n",
    "\n",
    "print(metrics.classification_report(newsgroups_test.target, predicted,\n",
    "    target_names=newsgroups_train.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Look at some of the performance variables available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.8241\n",
      "Avg recall, micro = 0.8241\n",
      "Avg recall, macro = 0.8237\n",
      "Avg precision, macro = 0.8604\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy = %6.4f\" % metrics.accuracy_score(newsgroups_test.target, predicted))\n",
    "\n",
    "print(\"Avg recall, micro = %6.4f\" % metrics.recall_score(newsgroups_test.target, \n",
    "                                                         predicted, \n",
    "                                                         average='micro'))  # same as accuracy\n",
    "      \n",
    "print(\"Avg recall, macro = %6.4f\" % metrics.recall_score(newsgroups_test.target, \n",
    "                                                         predicted, average='macro'))  # average of class recall\n",
    "\n",
    "print(\"Avg precision, macro = %6.4f\" % metrics.precision_score(newsgroups_test.target, \n",
    "                                                        predicted, average='macro'))  #average across class precision \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Investigate the impact of class imbalance on performance measures\n",
    "\n",
    "Build a classifier that predicts the categories 'talk.religion.misc' and 'soc.religion.christian' from the 20-newsgroups dataset.  \n",
    "Test it first on the training set.\n",
    "Test it also on the test set.  \n",
    "\n",
    "Add a markdown cell and include your observations on the following:\n",
    "* the class distribution of the training set  (evident from the classification report of testing on the training set -  support = the number of instances of each class)\n",
    "* the performance on the training set versus the performance on the test set and what does any difference here mean\n",
    "* which performance measure should be used.\n",
    "\n",
    "Note that a Jupyter notebooks Markdown Cheatsheet is available at https://medium.com/ibm-data-science-experience/markdown-for-jupyter-notebooks-cheatsheet-386c05aeebed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Investigate the impact of stopword removal and DF reduction on performance\n",
    "\n",
    "Build a classifier on at least 3 categories of the 20-newsgroup dataset.  Measure the performance including stopword removal and various levels of document frequency reduction.\n",
    "\n",
    "Add a markdown cell and outline your results showing the number of features used by the different settings and the impact on performance, if any.      \n",
    "\n",
    "Justify your choice of performance measure.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Investigate using different feature selection techniques\n",
    "\n",
    "Build a classifier on at least 3 categories of the 20-newsgroups dataset.  Select the top 100 features with and without both chi-squared feature selection.  Measure the performance on the test set.  \n",
    "\n",
    "In a markdown cell include your observations on the following:\n",
    "* can a reduced feature set meet the performance of the classifier on the full feature set?\n",
    "* how many features would you select to use on this dataset?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
